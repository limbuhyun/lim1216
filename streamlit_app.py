import os
import re
import json
import numpy as np
import pandas as pd
import streamlit as st
from openai import OpenAI

# -----------------------------
# 0) ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.set_page_config(page_title="AI ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

def get_secret(key: str, default=None):
    # Streamlit secrets -> env ìˆœìœ¼ë¡œ ì½ê¸°
    if key in st.secrets:
        return st.secrets[key]
    return os.getenv(key, default)

MODEL = get_secret("OPENAI_MODEL", "gpt-4.1-mini")

@st.cache_resource
def get_client():
    # OpenAI SDKëŠ” OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë„ ìë™ ì¸ì‹ ê°€ëŠ¥
    # (ì—¬ê¸°ì„œëŠ” st.secrets/envì—ì„œ ì½ì–´ ì§ì ‘ ì£¼ì…)
    api_key = get_secret("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return OpenAI(api_key=api_key)

client = get_client()

# -----------------------------
# 1) ìœ í‹¸: PII ë§ˆìŠ¤í‚¹
# -----------------------------
EMAIL_RE = re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
PHONE_RE = re.compile(r"(\+?\d{1,3}[-\s]?)?(\d{2,4}[-\s]?\d{3,4}[-\s]?\d{4})")

def mask_pii_text(s: str) -> str:
    s = EMAIL_RE.sub("[EMAIL]", s)
    s = PHONE_RE.sub("[PHONE]", s)
    return s

def mask_pii_df(df: pd.DataFrame, max_cells: int = 20000) -> pd.DataFrame:
    # í° ë°ì´í„°ëŠ” ë¹„ìš©/ì§€ì—° ë•Œë¬¸ì— "ì¼ë¶€ë§Œ" ë¬¸ìì—´ ë§ˆìŠ¤í‚¹
    out = df.copy()
    # ë¬¸ìì—´ ì¹¼ëŸ¼ë§Œ
    obj_cols = [c for c in out.columns if out[c].dtype == "object"]
    # ë„ˆë¬´ í¬ë©´ ì•ë¶€ë¶„ë§Œ
    if out.size > max_cells:
        out = out.head(max(50, min(500, len(out))))
    for c in obj_cols:
        out[c] = out[c].astype(str).map(mask_pii_text)
    return out

# -----------------------------
# 2) ë°ì´í„° ë¡œë”©
# -----------------------------
@st.cache_data
def load_data(file) -> pd.DataFrame:
    name = file.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(file)
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(file)
    raise ValueError("CSV ë˜ëŠ” Excelë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

# -----------------------------
# 3) EDA ìš”ì•½ ìƒì„±
# -----------------------------
def make_eda_summary(df: pd.DataFrame) -> dict:
    summary = {}
    summary["shape"] = list(df.shape)
    summary["columns"] = [{"name": c, "dtype": str(df[c].dtype), "missing": int(df[c].isna().sum())}
                          for c in df.columns]
    # ìˆ˜ì¹˜ ìš”ì•½
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if num_cols:
        desc = df[num_cols].describe().T.replace({np.nan: None})
        summary["numeric_describe"] = desc[["count","mean","std","min","25%","50%","75%","max"]].to_dict()
    else:
        summary["numeric_describe"] = {}

    # ë²”ì£¼í˜• ìƒìœ„ ê°’
    cat_cols = [c for c in df.columns if df[c].dtype == "object"]
    topcats = {}
    for c in cat_cols[:30]:
        vc = df[c].astype(str).value_counts(dropna=False).head(10)
        topcats[c] = [{"value": str(i), "count": int(vc[i])} for i in vc.index]
    summary["top_categories"] = topcats
    return summary

# -----------------------------
# 4) LLM: êµ¬ì¡°í™” ì¸ì‚¬ì´íŠ¸(JSON Schema)
# -----------------------------
INSIGHT_SCHEMA = {
  "name": "analysis_report",
  "schema": {
    "type": "object",
    "additionalProperties": False,
    "properties": {
      "one_line_summary": {"type": "string"},
      "key_insights": {
        "type": "array",
        "items": {
          "type": "object",
          "additionalProperties": False,
          "properties": {
            "title": {"type": "string"},
            "evidence": {"type": "string"},
            "why_it_matters": {"type": "string"},
            "recommended_next_step": {"type": "string"}
          },
          "required": ["title", "evidence", "why_it_matters", "recommended_next_step"]
        }
      },
      "data_quality_risks": {
        "type": "array",
        "items": {"type": "string"}
      },
      "statistical_notes": {
        "type": "array",
        "items": {"type": "string"}
      },
      "suggested_additional_analyses": {
        "type": "array",
        "items": {
          "type": "object",
          "additionalProperties": False,
          "properties": {
            "analysis": {"type": "string"},
            "how_to_do": {"type": "string"},
            "expected_output": {"type": "string"}
          },
          "required": ["analysis", "how_to_do", "expected_output"]
        }
      }
    },
    "required": ["one_line_summary", "key_insights", "data_quality_risks", "statistical_notes", "suggested_additional_analyses"]
  }
}

def llm_insights(df: pd.DataFrame, eda: dict, domain: str) -> dict:
    # ëª¨ë¸ì— ë³´ë‚´ëŠ” ë°ì´í„°ëŠ” "ìš”ì•½ + PII ë§ˆìŠ¤í‚¹ëœ ìƒ˜í”Œ"ë§Œ
    safe_df = mask_pii_df(df)
    sample_rows = safe_df.sample(min(30, len(safe_df)), random_state=42).to_dict(orient="records")

    system = (
        "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì±…ì„ì(Lead Data Scientist)ì…ë‹ˆë‹¤. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ ì£¼ì–´ì§„ JSON Schemaë¥¼ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤. "
        "ê³¼ì¥ ê¸ˆì§€, ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œë§Œ ì‘ì„±í•˜ê³ , í†µê³„ì  í•œê³„/í‘œë³¸ í¸í–¥ ê°€ëŠ¥ì„±ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
    )
    user = {
        "domain_context": domain,
        "eda_summary": eda,
        "masked_sample_rows": sample_rows
    }

    # Responses APIëŠ” OpenAIì˜ ìµœì‹  í†µí•© ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. :contentReference[oaicite:5]{index=5}
    resp = client.responses.create(
        model=MODEL,
        input=[
            {"role": "system", "content": system},
            {"role": "user", "content": json.dumps(user, ensure_ascii=False)}
        ],
        # Structured Outputs ê°€ì´ë“œ: JSON Schemaë¡œ ê°•ì œ :contentReference[oaicite:6]{index=6}
        text={
            "format": {
                "type": "json_schema",
                "json_schema": INSIGHT_SCHEMA
            }
        }
    )

    # SDK ë²„ì „ì— ë”°ë¼ ì ‘ê·¼ ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì•ˆì „ íŒŒì‹±
    # resp.output_textê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì•„ë‹ˆë©´ outputì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ë´„
    out_text = getattr(resp, "output_text", None)
    if not out_text:
        out_text = json.dumps(resp.model_dump(), ensure_ascii=False)

    # out_textëŠ” JSONì´ì–´ì•¼ í•¨
    return json.loads(out_text)

# -----------------------------
# 5) UI
# -----------------------------
st.title("ğŸ“Š AI ê¸°ë°˜ ì„¤ë¬¸/ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

with st.sidebar:
    st.header("ì„¤ì •")
    domain = st.text_input("ë¶„ì„ ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸", "ê³ ë“±í•™ìƒ ì‚¬êµìœ¡ë¹„/ì„¤ë¬¸ ë°ì´í„° ë¶„ì„")
    show_raw = st.checkbox("ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", True)
    run_ai = st.button("AI ì¸ì‚¬ì´íŠ¸ ìƒì„±")

file = st.file_uploader("CSV ë˜ëŠ” Excel ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"])

if file:
    df = load_data(file)
    st.success(f"ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")

    if show_raw:
        st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head(30), use_container_width=True)

    st.subheader("ê¸°ë³¸ EDA")
    eda = make_eda_summary(df)

    c1, c2 = st.columns(2)
    with c1:
        st.metric("í–‰ ìˆ˜", eda["shape"][0])
        st.metric("ì—´ ìˆ˜", eda["shape"][1])
    with c2:
        miss_total = sum(x["missing"] for x in eda["columns"])
        st.metric("ê²°ì¸¡ì¹˜ ì´í•©", miss_total)

    # ê²°ì¸¡ ìƒìœ„ ì—´
    miss_df = pd.DataFrame(eda["columns"]).sort_values("missing", ascending=False).head(15)
    st.write("ê²°ì¸¡ì¹˜ ìƒìœ„ 15ê°œ ì—´")
    st.dataframe(miss_df, use_container_width=True)

    # ìˆ˜ì¹˜í˜• ìš”ì•½ í‘œ
    if eda["numeric_describe"]:
        st.write("ìˆ˜ì¹˜í˜• ìš”ì•½(Describe)")
        desc = pd.DataFrame(eda["numeric_describe"])
        st.dataframe(desc, use_container_width=True)

    # AI ì¸ì‚¬ì´íŠ¸
    if run_ai:
        with st.spinner("AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘..."):
            report = llm_insights(df, eda, domain)

        st.subheader("AI ìš”ì•½")
        st.write(report["one_line_summary"])

        st.subheader("í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
        for i, ins in enumerate(report["key_insights"], 1):
            with st.expander(f"{i}. {ins['title']}"):
                st.markdown(f"**ê·¼ê±°**: {ins['evidence']}")
                st.markdown(f"**ì˜ë¯¸**: {ins['why_it_matters']}")
                st.markdown(f"**ë‹¤ìŒ ë‹¨ê³„**: {ins['recommended_next_step']}")

        st.subheader("ë°ì´í„° í’ˆì§ˆ/í•´ì„ ë¦¬ìŠ¤í¬")
        st.write(report["data_quality_risks"])

        st.subheader("í†µê³„ì  ìœ ì˜ì‚¬í•­")
        st.write(report["statistical_notes"])

        st.subheader("ì¶”ê°€ ë¶„ì„ ì œì•ˆ")
        for s in report["suggested_additional_analyses"]:
            st.markdown(f"- **{s['analysis']}**  \n  ë°©ë²•: {s['how_to_do']}  \n  ì‚°ì¶œë¬¼: {s['expected_output']}")

        # ë‹¤ìš´ë¡œë“œ(ë³´ê³ ì„œ JSON)
        st.download_button(
            "ğŸ“¥ ì¸ì‚¬ì´íŠ¸ JSON ë‹¤ìš´ë¡œë“œ",
            data=json.dumps(report, ensure_ascii=False, indent=2),
            file_name="ai_analysis_report.json",
            mime="application/json"
        )
else:
    st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
